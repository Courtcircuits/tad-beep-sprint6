# Q6: Production-Ready System

## Available Infrastructure

For Beep, we have nine servers available, each with the following configuration:

- **CPU**: 2
- **RAM**: 64GB
- **Disks**:
  - One SSD of 256GB
  - Two disks of 1.2TB

## Volumetry Estimation

**TO-DO**: Based on the scenario detailed below, I need to estimate how many requests per second Beep needs to fulfill.

Beep is a **real-time** messaging application that aims to be **scalable** and **available** to all users. We want to ensure that at least 99% of the time, the application is available and that it can handle the load of the users.

Currently, our user base is composed of around 50 users and can handle around 100 messages per second. We want to ensure that the application can handle 20,000 concurrent users across Europe. Let's assume that one user uses Beep for approximately one hour per day.

### Estimation Calculation

To estimate the number of requests per second Beep needs to fulfill, we start by considering the daily active users (DAU) and their average session duration. With 20,000 concurrent users, each using the application for about one hour per day, we can calculate the messages per second as follows:

Assuming each user sends or receives one message per minute, we have:

- **Messages per hour per user**: 60 messages
- **Total messages per hour**: 20,000 users * 60 messages = 1,200,000 messages
- **Messages per second**: 1,200,000 messages / 3600 seconds = 333 messages/second

Given this estimation, Beep needs to handle approximately 333 messages per second to support 20,000 concurrent users.

## Crisis Management

We want to be able to handle a crisis and recover quickly. Thus, if an outage occurs, the infrastructure should not lose any data. To achieve this, we will use a **PostgreSQL** database that will be replicated across multiple servers thanks to a High Availability (HA) setup. This setup will include one master write node and three read-only replicas. Additionally, backups of the database must be made and encrypted using AES-256 for security reasons.

To further enhance our crisis management capabilities, we will implement automated failover mechanisms to switch to a replica node in case the master node fails. Regular backups will be scheduled and stored in a secure, off-site location. Monitoring tools will be set up to detect anomalies and send alerts to the operations team. A disaster recovery plan will be developed and regularly tested to ensure quick recovery in case of a major outage.

## Networking for High Availability

To ensure high availability, we will implement several networking strategies. Redundant network paths will be used to avoid single points of failure. Load balancers will be deployed to distribute traffic evenly across servers. DNS failover will be configured to redirect traffic to a backup server in case the primary server fails. Health checks will be implemented to monitor the status of servers and remove unhealthy servers from the load balancer pool. These measures will help maintain the availability and reliability of the Beep application.

## Load Balancing

Istio is a service mesh that also provides a reverse proxy. According to [this benchmark](https://www.solo.io/blog/istio-grafana-k6), Istio can serve around 4,000 requests per second on a 1 CPU server, and this metric can go up to 25,000 requests per second on an 8 CPU server. Given our hardware infrastructure, we can handle at least 100,000 requests per second, which is significantly more than the estimated volumetry of 333 messages per second.

To further optimize load balancing, we will use Kubernetes to automatically scale the number of pods based on the load. Rate limiting will be implemented to prevent abuse and ensure fair usage of resources. Caching mechanisms will be used to reduce the load on the backend servers. Circuit breakers will be implemented to prevent cascading failures. These strategies will help distribute the load evenly and maintain the performance of the Beep application.

## Security

To ensure the security of the Beep application, we will implement several measures. Encryption will be used to protect data in transit and at rest. TLS/SSL will be used to encrypt data in transit, while AES-256 will be used to encrypt data at rest. Robust authentication and authorization mechanisms will be implemented to control access to the application. Intrusion detection systems will be deployed to monitor for suspicious activities. Regular security audits will be conducted to identify and fix vulnerabilities. These measures will help protect the Beep application and its users from security threats.

## Monitoring and Logging

To maintain the health and performance of the Beep application, we will implement several monitoring and logging strategies. A centralized logging system will be used to collect and analyze logs from all servers. Real-time monitoring tools will be deployed to track the performance and availability of the application. Alerts will be set up to notify the operations team of any issues or anomalies. Dashboards will be created to visualize key metrics and performance indicators. These measures will help us proactively identify and resolve issues, ensuring the reliability and performance of the Beep application.

## Scalability

To ensure that Beep can scale to handle increasing loads, we will implement several strategies. A microservices architecture will be used to decouple components and enable independent scaling. Kubernetes will be used to automatically scale the number of pods based on the load. Database sharding will be implemented to distribute the load across multiple database instances. A Content Delivery Network (CDN) will be used to cache static content and reduce the load on the origin servers. These strategies will help Beep scale horizontally and handle increasing loads efficiently.

By implementing these strategies, we can ensure that Beep is a production-ready, scalable, and highly available real-time messaging application.
